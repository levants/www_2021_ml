{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import numpy as np\n",
    "print(f'{sklearn.__version__} {xgboost.__version__} {lightgbm.__version__} {np.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install -U matplotlib pandas scikit-learn xgboost lightgbm umap-learn xopen orjson tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate number of CPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = multiprocessing.cpu_count()\n",
    "workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzBdwW7gPLsu"
   },
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Union, Any\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File locations for training and validation / test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data')\n",
    "DATA_DIR = path / 'www'\n",
    "DATA_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES_PATH = DATA_DIR / 'nodes.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls {DATA_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJbSJTyqpV2a"
   },
   "source": [
    "# Download the data from the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! gsutil -m cp gs://www21/nodes.joblib {NODES_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {DATA_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training data `X_train` and `y_train` and validation / test data `X_test` and `y_test` with `80% / 20%` ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = joblib.load(NODES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_distribution(frequencies:np.ndarray):\n",
    "    \"\"\"Plot distribution of labels\"\"\"\n",
    "    labels = ['tag', 'ad']\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.figure(figsize=(40, 40))\n",
    "    im = ax.imshow(frequencies, cmap='viridis', interpolation='nearest')\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "    ax.set_yticklabels([])\n",
    "    thresh = (frequencies.max() + frequencies.min()) / 2.0\n",
    "    cmap_min, cmap_max = im.cmap(0), im.cmap(256)\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            color = cmap_max if frequencies[i, j] < thresh else cmap_min\n",
    "            freq_val = labels[i] if j == 0 else frequencies[i, j]\n",
    "            text = ax.text(j, i, freq_val, ha='center', va='center', color=color)\n",
    "    ax.set_title('Distribution of tag / ad labels')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate data and label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tr, counts_tr = np.unique(y_train, return_counts=True)\n",
    "frequencies_tr = np.asarray((unique_tr, counts_tr)).T\n",
    "frequencies_tr\n",
    "print(f' nodes: {y_train.shape[0]}, ads: {counts_tr[1]}, ads%: {(y_train.shape[0] / counts_tr[1]) * 100:.2f}%')\n",
    "show_distribution(frequencies_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_ts, counts_ts = np.unique(y_test, return_counts=True)\n",
    "frequencies_ts = np.asarray((unique_ts, counts_ts)).T\n",
    "print(f' nodes: {y_test.shape[0]}, ads: {counts_ts[1]}, ads%: {(y_test.shape[0] / counts_ts[1]) * 100:.2f}%')\n",
    "show_distribution(frequencies_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count = y_train.shape[0] + y_test.shape[0]\n",
    "ad_count = counts_tr[1] + counts_ts[1]\n",
    "print(f' nodes: {node_count}, ads: {ad_count}, ads%: {(ad_count / node_count) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project nodes on `2D` plane with `UMAP` and `T-SNE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project node features on `2D` Euclidean plane preserving metrics (distances) between nodes using `UMAP` and `T-SNE` dimensionality reduction algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_nodes(X:np.ndarray, y:np.ndarray, num_classes:int=2, \n",
    "                  proj_type:type=UMAP, **kwargs) -> np.ndarray:\n",
    "    \"\"\"Project nodes on 2D plane\"\"\"\n",
    "    return proj_type(n_components=num_classes, **kwargs).fit_transform(X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot embeddings on `2D` plane "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nodes(z:np.ndarray, y:np.ndarray, colors:list,\n",
    "               proj_type:type=UMAP, num_classes:int=2, **kwargs):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(num_classes):\n",
    "        plt.scatter(z[y == i, 0], z[y == i, 1], s=20, color=colors[i])\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Node features via {proj_type.__name__} using Labels');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#ffc0cb', '#bada55']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embs_umap = project_nodes(X_test[:tail], y_test[:tail], proj_type=UMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_tsne = project_nodes(X_test[:tail], y_test[:tail], proj_type=TSNE, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nodes(embs_umap, y_test[:tail], colors, proj_type=UMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nodes(embs_tsne, y_test[:tail], colors, proj_type=TSNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train different tree based ensemble models on node features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement helper functions to analyze the model's performance:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- True positives\n",
    "- False positives\n",
    "- True negatives\n",
    "- False negatives\n",
    "- Confusion matrix\n",
    "and plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import ClassifierMixin, RegressorMixin\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, ConfusionMatrixDisplay, \n",
    "                             precision_recall_fscore_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cmx:np.ndarray):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    display_labels = ['tag', 'ad']\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cmx,\n",
    "                                  display_labels=display_labels)\n",
    "    disp = disp.plot(include_values=True,\n",
    "                     cmap='viridis', ax=None, xticks_rotation='horizontal',\n",
    "                     values_format=None, colorbar=True)\n",
    "    disp.ax_.set_title('Confusion matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_model(\n",
    "        y: np.ndarray,\n",
    "        y_pred: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    Validate performane on predictions\n",
    "    Args:\n",
    "        y (np.ndarray): true labels\n",
    "        y_pred (np.ndarray): predicted values\n",
    "\n",
    "    Returns:\n",
    "        val_acc (float): validation accuracy\n",
    "        pr_rc_f1 (float): validation f1 score\n",
    "        rep (dict): validation report dictionary\n",
    "        cmx (np.ndarray): confusion matrix\n",
    "    \"\"\"\n",
    "    val_acc = accuracy_score(y, y_pred, sample_weight=None)\n",
    "    target_names = ['tag', 'ad']\n",
    "\n",
    "    pr_rc_f1 = precision_recall_fscore_support(y, y_pred, beta=1.0,\n",
    "                                               average='binary')\n",
    "    rep = classification_report(y, y_pred, target_names=target_names,\n",
    "                                zero_division=0)\n",
    "    cmx = confusion_matrix(y, y_pred)\n",
    "\n",
    "    return val_acc, pr_rc_f1, rep, cmx\n",
    "\n",
    "\n",
    "def validate_model(\n",
    "        md: ClassifierMixin,\n",
    "        X: np.ndarray, y: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    validate model performance\n",
    "    Args:\n",
    "        md (Union[ClassifierMixin, RegressorMixin]): model to evaluate\n",
    "        X (np.ndarray): evaluation data\n",
    "        y (np.ndarray): evaluation labels\n",
    "\n",
    "    Returns:\n",
    "        val_acc (float): validation accuracy\n",
    "        pr_rc_f1 (float): validation F1 score\n",
    "        rep (dict): validation report dictionary\n",
    "        cmx: (np.ndaray): confusion matrix\n",
    "    \"\"\"\n",
    "    y_pred = md.predict(X)\n",
    "    val_acc, pr_rc_f1, rep, cmx = estimate_model(y, y_pred)\n",
    "\n",
    "    return val_acc, pr_rc_f1, rep, cmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_print(md, X, y):\n",
    "    acc, prf1, rep, cmx = validate_model(md, X, y)\n",
    "    tn, fp, fn, tp = cmx.ravel()\n",
    "    pr, rc, f1_sc, _ = prf1\n",
    "    print(f'accuracy: {acc:.4f}')\n",
    "    print(f'precision: {pr:.4f}, recall: {rc:.4f}, f1_score: {f1_sc:.4f}')\n",
    "    print(f'True positives: {tp}, false positives: {fp}, true negatives: {tn}, false negatives: {fn}')\n",
    "    plot_confusion_matrix(cmx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because ads distribution is small in comparison with tags if we just create a simple model which returns  $0$  no matter of input features, it will have high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(object):\n",
    "    \"\"\"Simple model which returns 0 no matter of input\"\"\"\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return np.zeros(X.shape[0], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's measure accuracy of our `SimpleModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SimpleModel()\n",
    "y_pred = sm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "simple_acc = np.mean(y_pred == y_test)\n",
    "print(f'accuracy: {simple_acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative mesures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define several estimations for binary classification:\n",
    "- True positives (`TP`): model's output is $1$ while the actual label is $1$\n",
    "- False positives (`FP`): model's output is $1$ while the actual label is $0$\n",
    "- True negatives (`TN`): model's output is $0$ while the actual label is $0$\n",
    "- False negatives (`FN`): model's output is $0$ while the actual label is $1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define precision and recall:\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$\n",
    "The measure of correct positive predictions overall positive predictions\n",
    "<br>\n",
    "and\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "$$\n",
    "The Measure of correct positive predictions overall positive labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to these measures `F1` score as:\n",
    "$$\n",
    "\\text{F1} = 2 \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "Which will estimate the model's performance on imbalanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_and_print(sm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, besides the fact that our `SimpleModel` has high accuracy, Precision and Recall and thus `F1` score are all  $0$  which gives a more robust estimation of our model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of training a single model, ensemble methods use multiple models to obtain better performance\n",
    "<br>\n",
    "For classification majority vote technique is used and averaging for final decision for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly weak estimators are used like `Decision Tree` with low depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrap aggregating (bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap aggregating (bagging) models are generated using the same algorithm with random sub-samples of the dataset which are drawn from the original dataset randomly with bootstrap sampling method with duplication.\n",
    "<br>\n",
    "We will train `Random Forest` bagging classifier on our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Random Forest` <a href=\"https://link.springer.com/article/10.1023/A:1010933404324\">paper</a> <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">scikit-learn</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting incrementally builds an ensemble by training each new model instance to on the errors of the previous instance:\n",
    "- `AdaBoosting` trains new models on weighted sample of training data with higher weights assigned to the part where the previous model had lower performance\n",
    "- `Gradient Boosting` trains each new instance on the errors (residuals) of the previous instance\n",
    "<br>\n",
    "We eill train `XGBoost` (Extrime Gradient Boosting) and `LightGBM` (Light Gradient Boosting Machine) boosting classifiers on our datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`XGBoost` - <a href=\"https://arxiv.org/abs/1603.02754\">paper</a> <a href=\"https://github.com/dmlc/xgboost\">project</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LightGBM` - <a href=\"https://www.microsoft.com/en-us/research/publication/lightgbm-a-highly-efficient-gradient-boosting-decision-tree/\">paper</a>\n",
    "<a href=\"https://github.com/microsoft/LightGBM\">project</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (confusion_matrix, precision_recall_fscore_support, \n",
    "                             classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change this parameters and train the model\n",
    "n_estimators = 128\n",
    "max_depth = 50\n",
    "min_samples_split = 8\n",
    "max_samples = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=0\n",
    "n_jobs=workers\n",
    "verbose=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = dict(n_estimators=n_estimators, max_depth=max_depth, \n",
    "                 min_samples_split=min_samples_split,\n",
    "                 max_samples=max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(**rf_params, random_state=random_state, \n",
    "                             n_jobs=n_jobs, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfc = rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'model: Random Forest classifier n_estimators={n_estimators} X max_depth{max_depth}')\n",
    "print()\n",
    "validate_and_print(rfc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_MODEL_PATH = DATA_DIR / 'rf_model.joblib'\n",
    "RF_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(rfc, RF_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De-serialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_ds = load(RF_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'model: Random Forest classifier n_estimators={n_estimators} X max_depth={max_depth}')\n",
    "print()\n",
    "validate_and_print(rfc_ds, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GXBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change this parameters and train the model\n",
    "n_estimators = 512\n",
    "max_depth = 8\n",
    "max_samples = 0.4\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_method = 'gpu_hist' #'exact' ##'approx' \n",
    "gpu_id=0 #None\n",
    "random_state=0\n",
    "n_jobs=workers\n",
    "verbose=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgc = xgb.XGBClassifier(n_estimators=n_estimators, use_label_encoder=False, tree_method=tree_method,\n",
    "                        max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                        learning_rate=learning_rate, verbosity=verbose, gpu_id=gpu_id,\n",
    "                        n_jobs=n_jobs, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgc.fit(X_train, y_train, eval_set=[(X_test, y_test)], \n",
    "        eval_metric = ['error'], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evals_result = xgc.evals_result()\n",
    "evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'model: XGBoost classifier n_estimators={n_estimators} X max_depth={max_depth}')\n",
    "print()\n",
    "validate_and_print(xgc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGC_MODEL_PATH = DATA_DIR / 'xgc_model.joblib'\n",
    "XGC_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(xgc, XGC_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgc_ds = load(XGC_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'model: XGBoost classifier n_estimators={n_estimators} X max_depth={max_depth}')\n",
    "print()\n",
    "validate_and_print(xgc_ds, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LightGBM classifierm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change this parameters and train the model\n",
    "n_estimators = 2048 * 2\n",
    "max_depth = 7\n",
    "max_samples = 0.4\n",
    "learning_rate=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GBM specific ##\n",
    "num_leaves=min(2**max_depth, 80)\n",
    "objective = 'binary'\n",
    "num_leaves = 128\n",
    "min_data_in_leaf = 800\n",
    "\n",
    "######################\n",
    "######################\n",
    "\n",
    "random_state=0\n",
    "n_jobs=-1\n",
    "verbose=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_essent = dict(n_estimators=n_estimators, max_depth=max_depth, \n",
    "                 objective=objective,\n",
    "                 num_leaves=num_leaves,\n",
    "                 min_data_in_leaf=min_data_in_leaf,\n",
    "                 learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_additional = dict(objective='binary',\n",
    "                     num_leaves=num_leaves,\n",
    "                     min_data_in_leaf=min_data_in_leaf,\n",
    "                     is_unbalance=True,\n",
    "                     boosting_type='gbdt',\n",
    "                     num_boost_round=12000,\n",
    "                     early_stopping_rounds=1000,\n",
    "                     bagging_freq=16,\n",
    "                     bagging_fraction=0.76,\n",
    "                     min_gain_to_split=0.24,\n",
    "                     silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_params = {**gb_essent, **gb_additional}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgc = lgb.LGBMClassifier(**gb_params, random_state=random_state, n_jobs=n_jobs, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgc = lgc.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'model: LightGBM classifier n_estimators={n_estimators} X max_depth={max_depth}')\n",
    "print()\n",
    "validate_and_print(lgc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGC_MODEL_PATH = DATA_DIR / 'lgc_model.joblib'\n",
    "LGC_MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(lgc, LGC_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgc_ds = load(LGC_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'model: LightGBM classifier n_estimators={n_estimators} X max_depth={max_depth}')\n",
    "print()\n",
    "validate_and_print(lgc_ds, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "abp_graph_data_processing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
